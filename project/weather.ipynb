{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc45c940",
   "metadata": {},
   "source": [
    "Analysis the wind speed around the country with a view to windfarms\n",
    "\n",
    "• You may look for your own source of historic weather information, and/or use the Met Eireann one (Historical Data - Met Éireann - The Irish Meteorological Service). Click on the download button to get a zip file that contains a CSV file.\n",
    "• You may need to clean and normalize the data before doing analysis\n",
    "• Questions you can ask:\n",
    "o How much wind power is there at a particular location?\n",
    "▪ This is quite open ended, is this just the mean wind speed for an hour/day/month/year, or should you take into account that\n",
    "there are wind ranges that the windfarms can operate in. (min max speeds)\n",
    "▪ Some analysis of what power when would be useful (time of day/year)\n",
    "o Are the wind speeds likely to be the same in 10 years in the future? ie is there a trend in recorded wind speeds over the last few decades.\n",
    "o Is there any other weather metric worth analyzing (eg rain, temp)\n",
    "o What will the power output of the windfarms in Ireland be like next week, according to the weather forecasts? (ok that is a tricky one, because you would need to get, or make up, information about the size and locations of the wind farms in Ireland, one find/makeup the windspeed to power output equation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24808bb6",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1/ Download data (hourly) from given website. \n",
    "2/ Upload the files on Github\n",
    "3/ Clean the file\n",
    "    - Remove all the rows above the Index row from the raw files\n",
    "    - Remove all the rows before the row where wdsp has its first value\n",
    "4/ Review the variable 'wdsp', convert the measurement of wind speed from knot into m/s\n",
    "5/ Add column 'dateonly' that contains dates (date-month-year) and column 'month' that contains months (month-year)\n",
    "\n",
    "Ref:\n",
    "https://en.wikipedia.org/wiki/Wind_power\n",
    "\n",
    "Ref:\n",
    "Wind turbines will generally operate between 7mph (11km/h) and 56mph (90km/h). The efficiency is usually maximised at about 18mph (29km/h) and they will reach their maximum output at 27mph (43km/h).\n",
    "\n",
    "https://www.nationalgrid.com/stories/energy-explained/wind-power-questions-answered#:~:text=Do%20turbines%20need%20fast%20wind,27mph%20(43km/h).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13c21f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7561c5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "For later calculation, I convert the measurement of wind speed from knot into m/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6812f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_with_station(file,station):\n",
    "\n",
    "    # Read file as text\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Find the row number where the data starts i.e. the row that contain 'date' in its first column\n",
    "    header_row = None\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        # split on comma and strip spaces\n",
    "        first_cell = line.split(\",\")[0].strip().lower()\n",
    "        if first_cell == \"date\":\n",
    "            header_row = i\n",
    "            break\n",
    "    \n",
    "    # Read file as csv, delete uneccessary rows\n",
    "    df = pd.read_csv(file, skiprows=header_row,low_memory=False)\n",
    "\n",
    "    # convert 'wdsp' to numeric\n",
    "    df[\"wdsp\"] = pd.to_numeric(df[\"wdsp\"], errors=\"coerce\")\n",
    "\n",
    "    # convert the measurement of wdsp into m/s\n",
    "    df[\"wdsp_ms\"] = df[\"wdsp\"] * 0.5144444444\n",
    "\n",
    "    # find first row where wind speed is not NaN\n",
    "    first_valid_value = df.loc[df[\"wdsp\"].notna()].index.min()\n",
    "\n",
    "    # drop rows before that\n",
    "    df = df.loc[first_valid_value:].reset_index(drop=True)\n",
    "\n",
    "    # modify the format of 'date'\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%d-%b-%Y %H:%M')\n",
    "\n",
    "    # Add a column which takes the station name as value\n",
    "    df[\"station\"]= station\n",
    "\n",
    "    # Add a column that contains only date details\n",
    "    df['dateonly']= df['date'].dt.date\n",
    "\n",
    "    # Add a column that contains only year\n",
    "    df['year'] = pd.to_datetime(df['date']).dt.strftime('%Y')\n",
    "\n",
    "    # Add a column that contains only month-year\n",
    "    df['yearmonth'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m')\n",
    "\n",
    "    # Add a column that contains only month\n",
    "    df['month'] = pd.to_datetime(df['date']).dt.strftime('%m')\n",
    "\n",
    "    # Add a column that contains only hour\n",
    "    df['hour'] = pd.to_datetime(df['date']).dt.strftime('%H:%M')\n",
    "\n",
    "    # convert 'temp' to numeric\n",
    "    df[\"temp\"] = pd.to_numeric(df[\"temp\"], errors=\"coerce\")\n",
    "    R = 287.05       # J/(kg·K)\n",
    "    p = 101325       # Pa (assumed constant)\n",
    "    # Add column 'rho' - air density\n",
    "    df[\"rho\"] = p / (R * (df[\"temp\"] + 273.15))\n",
    "\n",
    "    # Add column 'power' - wind power density\n",
    "    df['power'] = 0.5 * df[\"rho\"] * df[\"wdsp_ms\"]**3\n",
    "\n",
    "    # Save as a new file in folder stationdata\n",
    "    df.to_csv(f\"stationdata/{station}.csv\")\n",
    "    print(f\"The file {station}.csv is now created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "208056f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file MACE HEAD.csv is now created.\n",
      "The file OAK PARK.csv is now created.\n",
      "The file SHANNON AIRPORT.csv is now created.\n",
      "The file DUBLIN AIRPORT.csv is now created.\n",
      "The file MOORE PARK.csv is now created.\n",
      "The file BALLYHAISE.csv is now created.\n",
      "The file SHERKIN ISLAND.csv is now created.\n",
      "The file MULLINGAR.csv is now created.\n",
      "The file ROCHES POINT.csv is now created.\n",
      "The file NEWPORT.csv is now created.\n",
      "The file DUNSANY.csv is now created.\n",
      "The file GURTEEN.csv is now created.\n",
      "The file MALIN HEAD.csv is now created.\n",
      "The file JOHNSTOWN CASTLE 2.csv is now created.\n",
      "The file ATHENRY.csv is now created.\n",
      "The file MT DILLON.csv is now created.\n",
      "The file FINNER.csv is now created.\n",
      "The file CLAREMORRIS.csv is now created.\n",
      "The file VALENTIA OBSERVATORY.csv is now created.\n",
      "The file BELMULLET.csv is now created.\n",
      "The file CORK AIRPORT.csv is now created.\n",
      "The file KNOCK AIRPORT.csv is now created.\n"
     ]
    }
   ],
   "source": [
    "file_with_station(\"data/hly275.csv\",\"MACE HEAD\")\n",
    "file_with_station(\"data/hly375.csv\",\"OAK PARK\")\n",
    "file_with_station(\"data/hly518.csv\",\"SHANNON AIRPORT\")\n",
    "file_with_station(\"data/hly532.csv\",\"DUBLIN AIRPORT\")\n",
    "file_with_station(\"data/hly575.csv\",\"MOORE PARK\")\n",
    "file_with_station(\"data/hly675.csv\",\"BALLYHAISE\")\n",
    "file_with_station(\"data/hly775.csv\",\"SHERKIN ISLAND\")\n",
    "file_with_station(\"data/hly875.csv\",\"MULLINGAR\")\n",
    "file_with_station(\"data/hly1075.csv\",\"ROCHES POINT\")\n",
    "file_with_station(\"data/hly1175.csv\",\"NEWPORT\")\n",
    "file_with_station(\"data/hly1375.csv\",\"DUNSANY\")\n",
    "file_with_station(\"data/hly1475.csv\",\"GURTEEN\")\n",
    "file_with_station(\"data/hly1575.csv\",\"MALIN HEAD\")\n",
    "file_with_station(\"data/hly1775.csv\",\"JOHNSTOWN CASTLE 2\")\n",
    "file_with_station(\"data/hly1875.csv\",\"ATHENRY\")\n",
    "file_with_station(\"data/hly1975.csv\",\"MT DILLON\")\n",
    "file_with_station(\"data/hly2075.csv\",\"FINNER\")\n",
    "file_with_station(\"data/hly2175.csv\",\"CLAREMORRIS\")\n",
    "file_with_station(\"data/hly2275.csv\",\"VALENTIA OBSERVATORY\")\n",
    "file_with_station(\"data/hly2375.csv\",\"BELMULLET\")\n",
    "file_with_station(\"data/hly3904.csv\",\"CORK AIRPORT\")\n",
    "file_with_station(\"data/hly4935.csv\",\"KNOCK AIRPORT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c767694",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_with_station(\"data/hly375.csv\",\"OAK PARK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f31e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "oakpark = pd.read_csv(\"stationdata/OAK PARK.csv\")\n",
    "oakpark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f9973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variation of wind speed by month\n",
    "plt.figure(figsize=(15,4))\n",
    "monthly_wdsp = oakpark.groupby(\"month\")[\"wdsp_ms\"].mean()\n",
    "monthly_wdsp.plot(title=\"Monthly Mean Wind speed\")\n",
    "plt.xlabel('months of a year')\n",
    "plt.ylabel('Wind power')\n",
    "plt.grid(axis = 'y',color = 'green', linestyle = '--', linewidth = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34c2b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variation of power density by month\n",
    "plt.figure(figsize=(15,4))\n",
    "rho = 1.225  # air density kg/m^3\n",
    "oakpark[\"power_density\"] = 0.5 * rho * oakpark[\"wdsp_ms\"]**3\n",
    "monthly_power_density = oakpark.groupby(\"month\")[\"power_density\"].mean()\n",
    "monthly_power = oakpark.groupby(\"month\")[\"power\"].mean()\n",
    "monthly_power_density.plot(color='green')\n",
    "monthly_power.plot(color='orange')\n",
    "plt.title(\"Monthly Mean Wind Power Density\")\n",
    "plt.xlabel('months of a year')\n",
    "plt.ylabel('Wind power')\n",
    "plt.grid(axis = 'y',color = 'green', linestyle = '--', linewidth = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8143383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variation of power density by hour\n",
    "plt.figure(figsize=(15,4))\n",
    "hourly_power_density = oakpark.groupby(\"hour\")[\"power_density\"].mean()\n",
    "hourly_power = oakpark.groupby(\"hour\")[\"power\"].mean()\n",
    "hourly_power_density.plot(color='green')\n",
    "hourly_power.plot(color='orange')\n",
    "plt.title(\"Hourly Mean Wind Power Density\")\n",
    "plt.xlabel('hours of a day')\n",
    "plt.ylabel('Wind power')\n",
    "plt.grid(axis = 'y',color = 'green', linestyle = '--', linewidth = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55191707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variation of wind speed by month\n",
    "plt.figure(figsize=(15,4))\n",
    "hourly_wdsp = oakpark.groupby(\"hour\")[\"wdsp_ms\"].mean()\n",
    "hourly_wdsp.plot(title=\"Hourly Mean Wind speed\")\n",
    "plt.xlabel('hours of a day')\n",
    "plt.ylabel('Wind speed')\n",
    "plt.grid(axis = 'y',color = 'green', linestyle = '--', linewidth = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cff904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study wind speed range\n",
    "plt.hist(oakpark[\"wdsp_ms\"], bins=20)\n",
    "plt.xlabel(\"Wind speed (m/s)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Wind speed distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866381fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the wind range\n",
    "cut_in = 7\n",
    "optimum = 18     \n",
    "cut_out = 27 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d81c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study wind range for wind turbines operation\n",
    "oakpark[\"operating\"] = (oakpark[\"wdsp\"] >= 7) & (oakpark[\"wdsp\"] <= 27)\n",
    "oakpark[\"optimal\"]   = (oakpark[\"wdsp\"] >= 12) & (oakpark[\"wdsp\"] <= 18)\n",
    "\n",
    "# number of hours per day that the wind speed is in the operating range\n",
    "daily_hours = oakpark.groupby(\"dateonly\")[\"operating\"].sum()\n",
    "daily_avg = daily_hours.mean()\n",
    "\n",
    "daily_optimal = oakpark.groupby(\"dateonly\")[\"optimal\"].sum().mean()\n",
    "\n",
    "print(f'{daily_avg} & {daily_optimal}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae63f30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of hours per day that the wind speed is in the operating range\n",
    "monthly_hours = oakpark.groupby(\"month\")[\"operating\"].sum()\n",
    "monthly_avg = monthly_hours.mean()\n",
    "\n",
    "monthly_optimal = oakpark.groupby(\"month\")[\"optimal\"].sum().mean()\n",
    "print(f'{monthly_avg} & {monthly_optimal}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109af39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(monthly_hours.index, monthly_hours.values)\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Operating hours\")\n",
    "plt.title(\"Monthly wind turbine operating hours\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9cf76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_hours = oakpark.groupby(\"year\")[\"operating\"].sum()\n",
    "yearly_avg = yearly_hours.mean()\n",
    "\n",
    "yearly_optimal = oakpark.groupby(\"year\")[\"optimal\"].sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b28f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(yearly_hours.index, yearly_hours.values)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Operating hours\")\n",
    "plt.title(\"Yearly wind turbine operating hours\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd449d1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53db446d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stationinfo.csv is ready\n",
      "datestudy.csv is ready\n"
     ]
    }
   ],
   "source": [
    "# Folder contains all files with stations in column\n",
    "DATADIR = Path(\"stationdata\")\n",
    "#STATIONINFO = \"stationinfo.csv\"\n",
    "STUDYDATETILL2025 = \"studydate.csv\"\n",
    "\n",
    "# Create a list 'stationlist'\n",
    "stationlist = []\n",
    "\n",
    "# In each file in folder 'stationdata'\n",
    "for file in DATADIR.glob('*.csv'):\n",
    "    # Read only 2 columns 'station' and 'date'\n",
    "    df = pd.read_csv(file, usecols=[\"station\", \"date\"])\n",
    "    # Remove rows where 'date' is missing\n",
    "    #df = df[df[\"date\"].notna()]\n",
    "    # Convert the column 'date' to datetime\n",
    "    #df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "    # Get the station's name by getting the first row value of column 'station'\n",
    "    station_name = df[\"station\"].iloc[0]\n",
    "    # Get the start date of the station\n",
    "    start_date = df[\"date\"].min().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    # Get the end date of the station\n",
    "    end_date = df[\"date\"].max().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Write the infos above in 'stationlist'\n",
    "    stationlist.append({\n",
    "            \"station\": station_name,\n",
    "            \"startdate\": start_date,\n",
    "            \"enddate\": end_date\n",
    "        })\n",
    "# Save stationinfo.csv\n",
    "stationinfo_df = pd.DataFrame(stationlist)\n",
    "\n",
    "stationinfo_df.to_csv('stationinfo.csv', index=False)\n",
    "print(\"stationinfo.csv is ready\")\n",
    "\n",
    "\n",
    "# Step 2: Generate datestudy.csv: the idea behind this step is to set the same start date and end date for all stations, \n",
    "# to make the comparison simpler for later?\n",
    "\n",
    "# get the max start date among all stations\n",
    "#max_start = stationinfo_df[\"startdate\"].max()\n",
    "# get the max end date among all stations\n",
    "#max_end = stationinfo_df[\"enddate\"].max()\n",
    "\n",
    "# Data frame that contains all dates from max_start to max_end\n",
    "#all_dates = pd.date_range(start=max_start, end=max_end, freq=\"h\")\n",
    "\n",
    "# Save to datetill2025.csv\n",
    "#datestudy_df = pd.DataFrame({\"date\": all_dates})\n",
    "#datestudy_df.to_csv('datestudy.csv', index=False)\n",
    "#print(\"datestudy.csv is ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bda3a526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (3,5,7,8,9,10,11,13,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (13,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (3,5,7,8,9,10,11,13,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (7,8,9,10,11,13,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (7,13,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (7,13,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (7,9,10,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (3,5,7,8,9,10,11,13,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (3,5,7,8,9,10,11,13,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (3,5,7,8,9,10,11,13,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (5,7,8,9,11,13,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (3,5,7,8,9,10,11,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (3,5,7,8,9,10,11,13,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (3,5,7,8,9,10,13,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (3,5,7,8,9,10,11,13,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (3,5,7,8,9,10,11,13,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (3,7,8,9,10,13,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (3,5,7,8,9,10,11,13,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (3,5,7,8,9,10,11,13,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 station  startdate\n",
      "0                DUNSANY         13\n",
      "1              BELMULLET          1\n",
      "2     JOHNSTOWN CASTLE 2         34\n",
      "3            CLAREMORRIS        207\n",
      "4               CASEMENT          4\n",
      "5        SHANNON AIRPORT         12\n",
      "6         DUBLIN AIRPORT          0\n",
      "7           CORK AIRPORT          0\n",
      "8           ROCHES POINT         18\n",
      "9   VALENTIA OBSERVATORY         45\n",
      "10            BALLYHAISE         28\n",
      "11              OAK PARK          1\n",
      "12             MULLINGAR         13\n",
      "13            MOORE PARK          0\n",
      "14         KNOCK AIRPORT          0\n",
      "15             MACE HEAD         92\n",
      "16             MT DILLON         62\n",
      "17        SHERKIN ISLAND          5\n",
      "18               NEWPORT         76\n",
      "19            MALIN HEAD         52\n",
      "20                FINNER       7421\n",
      "21               ATHENRY         50\n",
      "22               GURTEEN         35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2567/3057289317.py:12: DtypeWarning: Columns (3,5,7,8,9,10,11,13,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  station_df = pd.read_csv(file)\n"
     ]
    }
   ],
   "source": [
    "stationinfo = pd.read_csv(\"stationinfo.csv\")\n",
    "# get the max start date among all stations\n",
    "max_start = stationinfo[\"startdate\"].max()\n",
    "\n",
    "DATADIR = Path(\"stationdata\")\n",
    "\n",
    "# Create a list\n",
    "sta_miss = []\n",
    "\n",
    "for file in DATADIR.glob('*.csv'):\n",
    "    # Read stations files\n",
    "    station_df = pd.read_csv(file)\n",
    "\n",
    "    # Keep only rows with dates in studydate.csv\n",
    "    station_df = station_df[station_df[\"date\"]>= max_start]\n",
    "    \n",
    "    # change the type on 'wdsp' to numeric, the missing value will be turned into NaN with parameter errors=\"coerce\"\n",
    "    station_df[\"wdsp\"] = pd.to_numeric(station_df[\"wdsp\"], errors=\"coerce\")\n",
    "\n",
    "    # count the number of missing values\n",
    "    station_df[\"wdsp\"].isna().sum()\n",
    "\n",
    "    # Skip stations with no remaining data\n",
    "    if station_df.empty:\n",
    "        continue\n",
    "\n",
    "    # Write the infos above in 'stationlist'\n",
    "    sta_miss.append({\n",
    "            \"station\": station_df[\"station\"].iloc[0],\n",
    "            \"startdate\": station_df[\"wdsp\"].isna().sum()\n",
    "        })\n",
    "    \n",
    "# Save stationinfo.csv\n",
    "sta_miss_df = pd.DataFrame(sta_miss)\n",
    "    # Save as a new file in folder stationdata\n",
    "    #station_df.to_csv(file, index=False)\n",
    "print(sta_miss_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2f85aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datestudy.csv')\n",
    "pd.api.types.is_datetime64_any_dtype(df[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "956aa0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(24)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the type on 'wdsp' to numeric, the missing value will be turned into NaN with parameter errors=\"coerce\"\n",
    "df[\"wdsp\"] = pd.to_numeric(df[\"wdsp\"], errors=\"coerce\")\n",
    "\n",
    "# count the number of missing values\n",
    "df[\"wdsp\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f2c468e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['date'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_3248/2510646409.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Set 'date' as index as interpolate based on actual time differences between index values\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = df.set_index(\u001b[33m'date'\u001b[39m)\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Interpolate missing windspeed (linear is best for meteorological data) -- I use AI to help me with this.\u001b[39;00m\n\u001b[32m      5\u001b[39m df[\u001b[33m'wdsp'\u001b[39m] = df[\u001b[33m'wdsp'\u001b[39m].interpolate(method=\u001b[33m'time'\u001b[39m, limit_direction=\u001b[33m'both'\u001b[39m, limit_area=\u001b[33m'inside'\u001b[39m)\n",
      "\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, keys, drop, append, inplace, verify_integrity)\u001b[39m\n\u001b[32m   6140\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m found:\n\u001b[32m   6141\u001b[39m                         missing.append(col)\n\u001b[32m   6142\u001b[39m \n\u001b[32m   6143\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[32m-> \u001b[39m\u001b[32m6144\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(f\"None of {missing} are in the columns\")\n\u001b[32m   6145\u001b[39m \n\u001b[32m   6146\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   6147\u001b[39m             frame = self\n",
      "\u001b[31mKeyError\u001b[39m: \"None of ['date'] are in the columns\""
     ]
    }
   ],
   "source": [
    "# Set 'date' as index as interpolate based on actual time differences between index values\n",
    "df = df.set_index('date')\n",
    "\n",
    "# Interpolate missing windspeed (linear is best for meteorological data) -- I use AI to help me with this.\n",
    "df['wdsp'] = df['wdsp'].interpolate(method='time', limit_direction='both', limit_area='inside')\n",
    "\n",
    "# count the number of missing values\n",
    "#df[\"wdsp\"].isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
