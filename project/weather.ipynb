{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b13c21f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5193d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_with_station(file,station):\n",
    "\n",
    "    # Read file as text\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Find the row number where the data starts i.e. the row that contain 'date' in its first column\n",
    "    header_row = None\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        # split on comma and strip spaces\n",
    "        first_cell = line.split(\",\")[0].strip().lower()\n",
    "        if first_cell == \"date\":\n",
    "            header_row = i\n",
    "            break\n",
    "    \n",
    "    # Read file as csv, delete uneccessary rows\n",
    "    df = pd.read_csv(file, skiprows=header_row,low_memory=False)\n",
    "    # modify the format of 'date'\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%d-%b-%Y %H:%M')\n",
    "    # Add a column which takes the station name as value\n",
    "    df[\"station\"]= station\n",
    "    # Add a column that contains only date details\n",
    "    df['dateonly']= df['date'].dt.date\n",
    "    # Add a column that contains only month-year\n",
    "    df['yearmonth'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m')\n",
    "    # Add a column that contains only month\n",
    "    df['month'] = pd.to_datetime(df['date']).dt.strftime('%m')\n",
    "    # Save as a new file in folder stationdata\n",
    "    df.to_csv(f\"stationdata/{station}.csv\")\n",
    "    print(f\"The file {station}.csv is now created.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "208056f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file MACE HEAD.csv is now created.\n",
      "The file OAK PARK.csv is now created.\n",
      "The file SHANNON AIRPORT.csv is now created.\n",
      "The file DUBLIN AIRPORT.csv is now created.\n",
      "The file MOORE PARK.csv is now created.\n",
      "The file BALLYHAISE.csv is now created.\n",
      "The file SHERKIN ISLAND.csv is now created.\n",
      "The file MULLINGAR.csv is now created.\n",
      "The file ROCHES POINT.csv is now created.\n",
      "The file NEWPORT.csv is now created.\n",
      "The file DUNSANY.csv is now created.\n",
      "The file GURTEEN.csv is now created.\n",
      "The file MALIN HEAD.csv is now created.\n",
      "The file JOHNSTOWN CASTLE 2.csv is now created.\n",
      "The file ATHENRY.csv is now created.\n",
      "The file MT DILLON.csv is now created.\n",
      "The file FINNER.csv is now created.\n",
      "The file CLAREMORRIS.csv is now created.\n",
      "The file VALENTIA OBSERVATORY.csv is now created.\n",
      "The file BELMULLET.csv is now created.\n",
      "The file CASEMENT.csv is now created.\n",
      "The file CORK AIRPORT.csv is now created.\n",
      "The file KNOCK AIRPORT.csv is now created.\n"
     ]
    }
   ],
   "source": [
    "file_with_station(\"data/hly275.csv\",\"MACE HEAD\")\n",
    "file_with_station(\"data/hly375.csv\",\"OAK PARK\")\n",
    "file_with_station(\"data/hly518.csv\",\"SHANNON AIRPORT\")\n",
    "file_with_station(\"data/hly532.csv\",\"DUBLIN AIRPORT\")\n",
    "file_with_station(\"data/hly575.csv\",\"MOORE PARK\")\n",
    "file_with_station(\"data/hly675.csv\",\"BALLYHAISE\")\n",
    "file_with_station(\"data/hly775.csv\",\"SHERKIN ISLAND\")\n",
    "file_with_station(\"data/hly875.csv\",\"MULLINGAR\")\n",
    "file_with_station(\"data/hly1075.csv\",\"ROCHES POINT\")\n",
    "file_with_station(\"data/hly1175.csv\",\"NEWPORT\")\n",
    "file_with_station(\"data/hly1375.csv\",\"DUNSANY\")\n",
    "file_with_station(\"data/hly1475.csv\",\"GURTEEN\")\n",
    "file_with_station(\"data/hly1575.csv\",\"MALIN HEAD\")\n",
    "file_with_station(\"data/hly1775.csv\",\"JOHNSTOWN CASTLE 2\")\n",
    "file_with_station(\"data/hly1875.csv\",\"ATHENRY\")\n",
    "file_with_station(\"data/hly1975.csv\",\"MT DILLON\")\n",
    "file_with_station(\"data/hly2075.csv\",\"FINNER\")\n",
    "file_with_station(\"data/hly2175.csv\",\"CLAREMORRIS\")\n",
    "file_with_station(\"data/hly2275.csv\",\"VALENTIA OBSERVATORY\")\n",
    "file_with_station(\"data/hly2375.csv\",\"BELMULLET\")\n",
    "file_with_station(\"data/hly3723.csv\",\"CASEMENT\")\n",
    "file_with_station(\"data/hly3904.csv\",\"CORK AIRPORT\")\n",
    "file_with_station(\"data/hly4935.csv\",\"KNOCK AIRPORT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93fbcc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = \"stationdata/\"\n",
    "db_path = \"stations.db\"\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS station_dates (\n",
    "    station TEXT,\n",
    "    date DATE\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fee7867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → loaded 195792 rows\n",
      "  → loaded 665435 rows\n",
      "  → loaded 186264 rows\n",
      "  → loaded 138192 rows\n",
      "  → loaded 560280 rows\n",
      "  → loaded 171504 rows\n",
      "  → loaded 709296 rows\n",
      "  → loaded 156408 rows\n",
      "  → loaded 257154 rows\n",
      "  → loaded 606658 rows\n",
      "  → loaded 709297 rows\n",
      "  → loaded 618768 rows\n",
      "  → loaded 195528 rows\n",
      "  → loaded 194184 rows\n",
      "  → loaded 241627 rows\n",
      "  → loaded 703464 rows\n",
      "  → loaded 183360 rows\n",
      "  → loaded 456408 rows\n",
      "  → loaded 594311 rows\n",
      "  → loaded 195792 rows\n",
      "  → loaded 189240 rows\n",
      "  → loaded 195504 rows\n",
      "  → loaded 517340 rows\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"stationdata\")\n",
    "\n",
    "for file in data_dir.glob(\"*.csv\"):\n",
    "    # Read only 2 columns: 'station' and 'date'\n",
    "    df = pd.read_csv(file, usecols=[\"station\", \"date\"])\n",
    "    # write to sqlite\n",
    "    df.to_sql(\n",
    "        \"station_dates\",\n",
    "        conn,\n",
    "        if_exists=\"append\",\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    print(f\"  → loaded {len(df)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "956aa0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(24)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the type on 'wdsp' to numeric, the missing value will be turned into NaN with parameter errors=\"coerce\"\n",
    "df[\"wdsp\"] = pd.to_numeric(df[\"wdsp\"], errors=\"coerce\")\n",
    "\n",
    "# count the number of missing values\n",
    "df[\"wdsp\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f2c468e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['date'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_3248/2510646409.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Set 'date' as index as interpolate based on actual time differences between index values\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = df.set_index(\u001b[33m'date'\u001b[39m)\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Interpolate missing windspeed (linear is best for meteorological data) -- I use AI to help me with this.\u001b[39;00m\n\u001b[32m      5\u001b[39m df[\u001b[33m'wdsp'\u001b[39m] = df[\u001b[33m'wdsp'\u001b[39m].interpolate(method=\u001b[33m'time'\u001b[39m, limit_direction=\u001b[33m'both'\u001b[39m, limit_area=\u001b[33m'inside'\u001b[39m)\n",
      "\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, keys, drop, append, inplace, verify_integrity)\u001b[39m\n\u001b[32m   6140\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m found:\n\u001b[32m   6141\u001b[39m                         missing.append(col)\n\u001b[32m   6142\u001b[39m \n\u001b[32m   6143\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[32m-> \u001b[39m\u001b[32m6144\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(f\"None of {missing} are in the columns\")\n\u001b[32m   6145\u001b[39m \n\u001b[32m   6146\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   6147\u001b[39m             frame = self\n",
      "\u001b[31mKeyError\u001b[39m: \"None of ['date'] are in the columns\""
     ]
    }
   ],
   "source": [
    "# Set 'date' as index as interpolate based on actual time differences between index values\n",
    "df = df.set_index('date')\n",
    "\n",
    "# Interpolate missing windspeed (linear is best for meteorological data) -- I use AI to help me with this.\n",
    "df['wdsp'] = df['wdsp'].interpolate(method='time', limit_direction='both', limit_area='inside')\n",
    "\n",
    "# count the number of missing values\n",
    "#df[\"wdsp\"].isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
